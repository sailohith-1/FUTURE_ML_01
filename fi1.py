# -*- coding: utf-8 -*-
"""FI1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FswkI-0tGSa-OyLgg1tgzBR_VqljFEFr
"""

# Sales Forecasting Dashboard using Superstore Dataset

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from prophet import Prophet
from prophet.diagnostics import cross_validation, performance_metrics
from prophet.plot import plot_cross_validation_metric

# Load dataset
df = pd.read_csv("/content/Sample - Superstore.csv", encoding="ISO-8859-1")

# Drop irrelevant columns
df.drop(columns=[
    'Row ID','Order ID','Customer ID','Customer Name',
    'Postal Code','Product ID'
], inplace=True)

# Convert date columns
df['Order Date'] = pd.to_datetime(df['Order Date'])
df['Ship Date'] = pd.to_datetime(df['Ship Date'])

# Create time features
df['year'] = df['Order Date'].dt.year
df['month'] = df['Order Date'].dt.month
df['week'] = df['Order Date'].dt.isocalendar().week
df['day'] = df['Order Date'].dt.day
df['day of week'] = df['Order Date'].dt.day_of_week

df.drop_duplicates(inplace=True)

# EDA
plt.figure(figsize=(8,5))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap="coolwarm")
plt.title("Correlation Heatmap")
plt.show()

plt.figure(figsize=(8,5))
sns.histplot(df['Sales'], bins=50, kde=True)
plt.title("Sales Distribution")
plt.show()

plt.figure(figsize=(8,5))
sns.histplot(df['Profit'], bins=50, kde=True)
plt.title("Profit Distribution")
plt.show()

plt.figure(figsize=(7,5))
sns.barplot(x='Category', y='Sales', data=df, estimator=sum)
plt.title("Total Sales by Category")
plt.show()

plt.figure(figsize=(12,5))
sns.barplot(x='Sub-Category', y='Sales', data=df, estimator=sum)
plt.xticks(rotation=45)
plt.title("Total Sales by Sub-Category")
plt.show()

plt.figure(figsize=(7,5))
sns.barplot(x='Region', y='Sales', data=df, estimator=sum)
plt.title("Total Sales by Region")
plt.show()

plt.figure(figsize=(7,5))
sns.barplot(x='Segment', y='Sales', data=df, estimator=sum)
plt.title("Total Sales by Segment")
plt.show()

# Aggregate daily sales
daily_sales = df.groupby('Order Date')['Sales'].sum().reset_index()
daily_sales.rename(columns={'Order Date':'ds','Sales':'y'}, inplace=True)

plt.figure(figsize=(14,6))
plt.plot(daily_sales['ds'], daily_sales['y'])
plt.title('Daily Sales Over Time')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.show()

# Handle outliers in Profit
Q1 = df['Profit'].quantile(0.25)
Q3 = df['Profit'].quantile(0.75)
IQR = Q3 - Q1
upper_bound = Q3 + 1.5 * IQR
df['Profit'] = np.where(df['Profit'] > upper_bound, upper_bound, df['Profit'])

# Define holidays
holidays = pd.DataFrame({
    'holiday': ['Black Friday']*4 + ['Christmas']*4 + ['New Year']*4,
    'ds': pd.to_datetime([
        '2014-11-28','2015-11-27','2016-11-25','2017-11-24',
        '2014-12-25','2015-12-25','2016-12-25','2017-12-25',
        '2015-01-01','2016-01-01','2017-01-01','2018-01-01'
    ]),
    'lower_window': 0,
    'upper_window': 1
})

# Train Prophet model
model = Prophet(
    holidays=holidays,
    yearly_seasonality=True,
    weekly_seasonality=True,
    daily_seasonality=False
)
model.add_seasonality(name='monthly', period=30.5, fourier_order=5)

daily_sales['y'] = np.log1p(daily_sales['y'])
model.fit(daily_sales)

# Forecast
future = model.make_future_dataframe(periods=180)
forecast = model.predict(future)

fig1 = model.plot(forecast)
plt.title('Forecast of Daily Sales')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.show()

fig2 = model.plot_components(forecast)
plt.show()

# Cross-validation
df_cv = cross_validation(model,
                         initial='730 days',
                         period='180 days',
                         horizon='90 days')
df_p = performance_metrics(df_cv)
print(df_p.head())

fig = plot_cross_validation_metric(df_cv, metric='mape')
plt.show()

# Evaluation metrics
from sklearn.metrics import mean_absolute_error, mean_squared_error

df_merged = pd.merge(daily_sales, forecast[['ds','yhat']], on='ds', how='inner')
mae = mean_absolute_error(df_merged['y'], df_merged['yhat'])
rmse = np.sqrt(mean_squared_error(df_merged['y'], df_merged['yhat']))
mape = np.mean(np.abs((df_merged['y']-df_merged['yhat'])/df_merged['y']))*100

print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"MAPE: {mape:.2f}%")

# Save merged dataset
df_merged.to_csv('historical_and_forecast_sales.csv', index=False)

# Export future forecast only
last_date = daily_sales['ds'].max()
future_forecast = forecast[forecast['ds'] > last_date]
future_forecast[['ds','yhat','yhat_lower','yhat_upper']].to_csv('future_forecasted_sales.csv', index=False)

# Save historical sales
daily_sales.to_csv('historical_daily_sales.csv', index=False)

# Save metrics
metrics = {
    "Metric": ["MAE","RMSE","MAPE"],
    "Value": [mae, rmse, mape]
}
metrics_df = pd.DataFrame(metrics)
metrics_df.to_csv("forecast_metrics.csv", index=False)